{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Variables\n",
    "train_num = 50000\n",
    "valid_num = 20000\n",
    "test_num = 25000\n",
    "width = 32\n",
    "height = 32\n",
    "num_channels = 1\n",
    "labels = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (50000, 32, 32, 3)\n",
      "Train labels shape: (50000, 1)\n",
      "Valid data shape: (20000, 32, 32, 3)\n",
      "Valid labels shape: (20000, 1)\n",
      "Test data shape: (25000, 32, 32, 3)\n",
      "Test labels shape: (25000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load small training and testing data and labels into memory\n",
    "train_mat = scipy.io.loadmat('svhn_small/train_32x32.mat')\n",
    "test_mat = scipy.io.loadmat('svhn_small/test_32x32.mat')\n",
    "train_X = np.rollaxis(train_mat['X'][:,:,:,:train_num], 3)\n",
    "train_y = train_mat['y'][:train_num,:]\n",
    "valid_X = np.rollaxis(train_mat['X'][:,:,:,train_num:train_num + valid_num], 3)\n",
    "valid_y = train_mat['y'][train_num:train_num + valid_num,:]\n",
    "test_X = np.rollaxis(test_mat['X'][:,:,:,:test_num], 3)\n",
    "test_y = test_mat['y'][:test_num,:]\n",
    "\n",
    "print 'Train data shape: ' + str(train_X.shape)\n",
    "print 'Train labels shape: ' +  str(train_y.shape)\n",
    "print 'Valid data shape: ' + str(valid_X.shape)\n",
    "print 'Valid labels shape: ' +  str(valid_y.shape)\n",
    "print 'Test data shape: ' + str(test_X.shape)\n",
    "print 'Test labels shape: ' + str(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data grayscale shape: (32, 32, 50000)\n",
      "Valid data grayscale shape: (32, 32, 20000)\n",
      "Test data grayscale shape: (32, 32, 25000)\n"
     ]
    }
   ],
   "source": [
    "# Convert images to grayscale\n",
    "train_X_gray = np.ndarray((width, height, train_num))\n",
    "valid_X_gray = np.ndarray((width, height, valid_num))\n",
    "test_X_gray = np.ndarray((width, height, test_num))\n",
    "\n",
    "for i in xrange(train_num):\n",
    "    train_X_gray[:,:,i] = color.rgb2gray(train_X[:,:,:,i])\n",
    "\n",
    "for i in xrange(valid_num):\n",
    "    valid_X_gray[:,:,i] = color.rgb2gray(valid_X[:,:,:,i])\n",
    "    \n",
    "for i in xrange(test_num):\n",
    "    test_X_gray[:,:,i] = color.rgb2gray(test_X[:,:,:,i])\n",
    "    \n",
    "print 'Train data grayscale shape: ' + str(train_X_gray.shape)\n",
    "print 'Valid data grayscale shape: ' + str(valid_X_gray.shape)\n",
    "print 'Test data grayscale shape: ' + str(test_X_gray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Lets look at a couple images\n",
    "# %matplotlib inline\n",
    "# for i in range(10):\n",
    "#     plt.figure()\n",
    "#     plt.imshow(test_X_gray[:,:,i])\n",
    "#     print test_y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Run some simple tests via sklearn\n",
    "# train_X_flat = np.reshape(train_X_gray, (train_num, width * height))\n",
    "# test_X_flat = np.reshape(test_X_gray, (test_num, width * height))\n",
    "\n",
    "# clf= SVC()\n",
    "# clf.fit(train_X_flat[:1000], train_y[:1000])\n",
    "# print clf.score(test_X_flat[:1000], test_y[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Randomize data\n",
    "def randomize(data, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_data = data[:,:,permutation]\n",
    "    shuffled_labels = labels[permutation,:]\n",
    "    return shuffled_data, shuffled_labels\n",
    "train_X_gray, train_y = randomize(train_X_gray, train_y)\n",
    "valid_X_gray, valid_y = randomize(valid_X_gray, valid_y)\n",
    "test_X_gray, test_y = randomize(test_X_gray, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 1: 9440\n",
      "Train 2: 7227\n",
      "Train 3: 5850\n",
      "Train 4: 5108\n",
      "Train 5: 4641\n",
      "Train 6: 3903\n",
      "Train 7: 3830\n",
      "Train 8: 3419\n",
      "Train 9: 3186\n",
      "Train 10: 3396\n",
      "Valid 1: 3828\n",
      "Valid 2: 2910\n",
      "Valid 3: 2257\n",
      "Valid 4: 2028\n",
      "Valid 5: 1908\n",
      "Valid 6: 1553\n",
      "Valid 7: 1516\n",
      "Valid 8: 1396\n",
      "Valid 9: 1272\n",
      "Valid 10: 1332\n",
      "Test 1: 4902\n",
      "Test 2: 3989\n",
      "Test 3: 2775\n",
      "Test 4: 2423\n",
      "Test 5: 2287\n",
      "Test 6: 1897\n",
      "Test 7: 1928\n",
      "Test 8: 1606\n",
      "Test 9: 1523\n",
      "Test 10: 1670\n"
     ]
    }
   ],
   "source": [
    "train_lens = []\n",
    "valid_lens = []\n",
    "test_lens = []\n",
    "\n",
    "for i in xrange(1, 11):\n",
    "    print 'Train ' + str(i) + ': ' + str(len([x[0] for x in train_y.tolist() if x[0] == i]))\n",
    "    \n",
    "for i in xrange(1, 11):\n",
    "    print 'Valid ' + str(i) + ': ' + str(len([x[0] for x in valid_y.tolist() if x[0] == i]))\n",
    "    \n",
    "for i in xrange(1, 11):\n",
    "    print 'Test ' + str(i) + ': ' + str(len([x[0] for x in test_y.tolist() if x[0] == i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (32, 32, 1, 50000)\n",
      "Train labels shape: (50000, 10)\n",
      "Valid data shape: (32, 32, 1, 20000)\n",
      "Valid labels shape: (20000, 10)\n",
      "Test data shape: (32, 32, 1, 25000)\n",
      "Test labels shape: (25000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Reshape data and labels for TensorFlow\n",
    "train_X_gray = train_X_gray.reshape(width, height, num_channels, train_num).astype(np.float32)\n",
    "train_y = (labels == train_y[:]).astype(np.float32)\n",
    "valid_X_gray = valid_X_gray.reshape(width, height, num_channels, valid_num).astype(np.float32)\n",
    "valid_y = (labels == valid_y[:]).astype(np.float32)\n",
    "test_X_gray = test_X_gray.reshape(width, height, num_channels, test_num).astype(np.float32)\n",
    "test_y = (labels == test_y[:]).astype(np.float32)\n",
    "\n",
    "print 'Train data shape: ' + str(train_X_gray.shape)\n",
    "print 'Train labels shape: ' +  str(train_y.shape)\n",
    "print 'Valid data shape: ' + str(valid_X_gray.shape)\n",
    "print 'Valid labels shape: ' +  str(valid_y.shape)\n",
    "print 'Test data shape: ' + str(test_X_gray.shape)\n",
    "print 'Test labels shape: ' + str(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions Dimension(20000) and Dimension(1) are not compatible",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-172-bad53e29fbae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;31m# Predictions for the training, validation, and test data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mtrain_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mvalid_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_valid_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[0mtest_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_test_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-172-bad53e29fbae>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# Model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mconv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer1_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SAME'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlayer1_biases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mconv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer2_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SAME'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.pyc\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, name)\u001b[0m\n\u001b[0;32m    209\u001b[0m   return _op_def_lib.apply_op(\"Conv2D\", input=input, filter=filter,\n\u001b[0;32m    210\u001b[0m                               \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m                               use_cudnn_on_gpu=use_cudnn_on_gpu, name=name)\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    653\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    654\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    656\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_Restructure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_n_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2040\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0;32m   2041\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2042\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2043\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2044\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1526\u001b[0m       raise RuntimeError(\"No shape function registered for standard op: %s\"\n\u001b[0;32m   1527\u001b[0m                          % op.type)\n\u001b[1;32m-> 1528\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1529\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1530\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/common_shapes.pyc\u001b[0m in \u001b[0;36mconv2d_shape\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m    185\u001b[0m   \u001b[0mdepth_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m   \u001b[1;31m# Check that the input depths are compatible.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m   \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m   \u001b[0mstride_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride_d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"strides\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m       raise ValueError(\"Dimensions %s and %s are not compatible\"\n\u001b[1;32m---> 94\u001b[1;33m                        % (self, other))\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mmerge_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions Dimension(20000) and Dimension(1) are not compatible"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data.\n",
    "    tf_train_X = tf.placeholder(tf.float32, shape=(batch_size, width, height, num_channels))\n",
    "    tf_train_y = tf.placeholder(tf.float32, shape=(batch_size, len(labels)))\n",
    "    tf_valid_X = tf.constant(valid_X_gray)\n",
    "    tf_test_X = tf.constant(test_X_gray)\n",
    "    \n",
    "    # Variables.\n",
    "    layer1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "    layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "    layer2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "    layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "    layer3_weights = tf.Variable(tf.truncated_normal([width // 4 * height // 4 * depth, num_hidden], stddev=0.1))\n",
    "    layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "    layer4_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))\n",
    "    layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "    \n",
    "    # Model.\n",
    "    def model(data):\n",
    "        conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + layer1_biases)\n",
    "        conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + layer2_biases)\n",
    "        shape = hidden.get_shape().as_list()\n",
    "        reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "        hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "        return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "    \n",
    "    # Training computation.\n",
    "    logits = model(tf_train_X)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_y))\n",
    "      \n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(model(tf_valid_X))\n",
    "    test_prediction = tf.nn.softmax(model(tf_test_X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
